import os
import threading
import contextlib
import io
import json
import random
import asyncio
import logging
import traceback
import ast
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
import nest_asyncio

nest_asyncio.apply()

# Set up logging
LOG_FILE_PATH = '/mnt/data/.io/debug.log'
os.makedirs(os.path.dirname(LOG_FILE_PATH), exist_ok=True)
logging.basicConfig(filename=LOG_FILE_PATH, level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')

FINAL_RESULTS_DIR = '/mnt/data/.io/final_results'
FUNCTION_CALLS_PATH = '/mnt/data/.io/function_calls.txt'
RESULTS_DIR = '/mnt/data/.io/function_results'

# Global context to share between the main runner and executed code
global_context = {}
class functions: pass

class FileHandler(FileSystemEventHandler):
    def __init__(self, queue, event_loop):
        self.queue = queue
        self.event_loop = event_loop

    def on_created(self, event):
        if not event.is_directory and event.src_path.endswith('.py'):
            logging.debug(f"File created: {event.src_path}")
            self.event_loop.call_soon_threadsafe(self.queue.put_nowait, event.src_path)

    def on_modified(self, event):
        if not event.is_directory and event.src_path.endswith('.py'):
            logging.debug(f"File modified: {event.src_path}")
            self.event_loop.call_soon_threadsafe(self.queue.put_nowait, event.src_path)

class ResultFileHandler(FileSystemEventHandler):
    def __init__(self, loop, result_event, result_path):
        self.loop = loop
        self.result_event = result_event
        self.result_path = result_path

    def on_created(self, event):
        if event.src_path == self.result_path:
            self.loop.call_soon_threadsafe(self.result_event.set)

    def on_modified(self, event):
        if event.src_path == self.result_path:
            self.loop.call_soon_threadsafe(self.result_event.set)

async def poll_function_result(key, loop):
    result_path = os.path.join(RESULTS_DIR, f'{key}.json')
    result_event = asyncio.Event()

    # Check if the result file already exists
    if os.path.exists(result_path):
        with open(result_path, 'r') as f:
            result = json.load(f)
        os.remove(result_path)
        return result

    # Set up watchdog observer for the result file
    event_handler = ResultFileHandler(loop, result_event, result_path)
    observer = Observer()
    observer.schedule(event_handler, path=RESULTS_DIR, recursive=False)
    observer.start()

    try:
        await result_event.wait()  # Wait for the event to be set when the file is created

        with open(result_path, 'r') as f:
            result = json.load(f)
        os.remove(result_path)
        return result
    except json.JSONDecodeError:
        os.remove(result_path)
        return None
    finally:
        observer.stop()
        observer.join()

async def execute_with_last_result(code):
    if not code.strip():
        return None, "", ""

    output, error = io.StringIO(), io.StringIO()
    parsed_code = ast.parse(code)
    last_expr, last_stmt = None, None
    is_async = False

    for node in reversed(parsed_code.body):
        if isinstance(node, ast.Expr):
            last_expr = node
            if isinstance(node.value, ast.Await):
                is_async = True
            parsed_code.body.remove(node)
            break
        elif isinstance(node, (ast.FunctionDef, ast.ClassDef, ast.Assign, ast.AugAssign, ast.AnnAssign)):
            last_stmt = node
            if isinstance(node, ast.AsyncFunctionDef):
                is_async = True
            parsed_code.body.remove(node)
            break

    local_context = {}

    try:
        with contextlib.redirect_stdout(output), contextlib.redirect_stderr(error):
            exec(compile(parsed_code, filename="<ast>", mode="exec"), global_context, local_context)
            if last_expr:
                if is_async:
                    logging.debug(f"Evaluating async last expression: {ast.dump(last_expr)}")
                    last_result = await eval(compile(ast.Expression(last_expr.value), filename="<ast>", mode="eval"), global_context, local_context)
                else:
                    logging.debug(f"Evaluating last expression: {ast.dump(last_expr)}")
                    last_result = eval(compile(ast.Expression(last_expr.value), filename="<ast>", mode="eval"), global_context, local_context)
            elif last_stmt:
                module = ast.Module(body=[last_stmt], type_ignores=[])
                if is_async:
                    await exec(compile(module, filename="<ast>", mode="exec"), global_context, local_context)
                else:
                    exec(compile(module, filename="<ast>", mode="exec"), global_context, local_context)
                last_result = None
            else:
                last_result = None
    except Exception:
        error.write(traceback.format_exc())
        last_result = None

    # Update the global context with the local context
    global_context.update(local_context)

    stdout_output = output.getvalue().strip()
    stderr_output = error.getvalue().strip()

    return last_result, stdout_output, stderr_output

async def process_queue(queue):
    while True:
        file_path = await queue.get()
        if file_path is None:
            break

        final_results_path = os.path.join(FINAL_RESULTS_DIR, f'{os.path.basename(file_path).replace(".py", ".json")}')

        try:
            logging.debug(f"Processing file: {file_path}")
            with open(file_path, 'r') as file:
                code = file.read()
            logging.debug(f"File content of {file_path}: {code}")

            result, stdout, stderr = await execute_with_last_result(code)

            output = {
                "stdout": stdout,
                "stderr": stderr,
                "result": json.dumps(result)
            }
            logging.debug(f"Output for {file_path}: {output}")
            with open(final_results_path, 'w') as result_file:
                result_file.write(json.dumps(output) + '\n')
            logging.debug(f"Written result for file: {file_path}")
        except Exception as ex:
            logging.error(f"Error processing {file_path}: {ex}")
            with open(final_results_path, 'w') as result_file:
                result_file.write(json.dumps({"stdout": stdout, "stderr": traceback.format_exc()}) + '\n')
        finally:
            queue.task_done()

def main():
    directory_to_watch = '/mnt/data/.main/'
    if not os.path.exists(directory_to_watch):
        logging.error(f"Directory {directory_to_watch} does not exist")
        return

    loop = asyncio.get_event_loop()
    file_queue = asyncio.Queue()

    # Check if there are any existing files in the directory
    for filename in os.listdir(directory_to_watch):
        file_path = os.path.join(directory_to_watch, filename)
        if os.path.isfile(file_path) and file_path.endswith('.py'):
            file_queue.put_nowait(file_path)

    event_handler = FileHandler(file_queue, loop)
    observer = Observer()
    observer.schedule(event_handler, path=directory_to_watch, recursive=False)
    observer.start()
    logging.debug(f"Started observer on {directory_to_watch}")

    processing_task = loop.create_task(process_queue(file_queue))
    logging.debug("Started processing task")

    try:
        loop.run_forever()
    except KeyboardInterrupt:
        observer.stop()
    finally:
        observer.join()
        file_queue.put_nowait(None)
        loop.run_until_complete(processing_task)
        loop.close()

if __name__ == "__main__":
    main()
